<configuration>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <target>System.out</target>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
        </filter>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>/Users/Ryuichi/IdeaProjects/LogControlExperiment/src/main/scala-2.11/jp/ac/keio/sdm/ConcurrentLogControl/LogControlExmeriment.log</file>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>WARN</level>
        </filter>
        <!--<file>/mnt/var/log/application/application.log</file>-->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- <fileNamePattern>/var/log/info-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern> -->
            <!--Development Mode-->
            <fileNamePattern>/Users/Ryuichi/IdeaProjects/LogControlExperiment/src/main/scala-2.11/jp/ac/keio/sdm/ConcurrentLogControl/%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <!--Product Mode-->
            <!--<fileNamePattern>/jp/ac/keio/sdm/ConcurrentLogControl/%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>-->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>1GB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!--<logger name = "org.apache.spark" level = "WARN" />-->
    <!--<logger name = "org.apache.spark.streaming.NetworkInputTracker" level = "INFO" />-->

    <root level="INFO">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="FILE"/>
    </root>

</configuration>